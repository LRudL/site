- label: sad
  title: "Me, Myself, and AI: The Situational Awareness Dataset (SAD) for LLMs"
  date: 2024-07-08
  description: "We build a comprehensive benchmark to measure situational awareness in LLMs. It consists of 16 tasks, which we group into 7 categories and 3 aspects of situational awareness (self-knowledge, situational inferences, and taking actions)."
  math: false
  type: ["project reports"]
  tags: ["AI"]
  coauthors: ["Bilal Chughtai", "Jan Betley", "Kaivu Hariharan", "Jeremy Scheurer", "Mikita Balesni", "Alex Meinke", "Marius Hobbhahn", "Owain Evans"]
  elsewhere: ["https://www.lesswrong.com/posts/YsCRXZYr5DcJ84XHq/me-myself-and-ai-the-situational-awareness-dataset-sad-for"]

- label: wisdom1
  title: "AI & wisdom 1: wisdom, amortised optimisation, and AI"
  date: 2024-10-12
  description: A lot of what we call wisdom is about mental qualities shaped more by amortised optimisation than direct optimisation. Direct optimisation is solving problems by searching through alternatives on the fly, while amortised optimisation is solving a problem by applying past data and computation.
  math: true
  type: ["general"]
  tags: ["civilisation"]
  sequel: wisdom2

- label: wisdom2
  title: "AI & wisdom 2: growth and amortised optimisation"
  date: 2024-10-13
  description: Amortised optimisation matters more when growth and change are slow, so the relative importance of it will likely decline with the growth and changed caused by AI. However, a model suggests it's hard for amortised optimisation to entirely decline in relevance.
  math: true
  type: ["general"]
  tags: ["civilisation"]
  sequel: wisdom3
  prequel: wisdom1

- label: wisdom3
  title: "AI & wisdom 3: AI effects on amortised optimisation"
  date: 2024-10-14
  description: Human amortised optimisation is enabled by things like cultural evolution and written knowledge. Advanced AI may weaken human cultural evolution, but may themselves be very good at it due to their low copying costs. AIs might help humans distil insights from written knowledge, but ultimately replace the need for it. I also discuss trying to use AI to avoid large-scale strategy or framing errors. 
  math: true
  type: ["general"]
  tags: ["civilisation", "AI"]
  prequel: wisdom2

- label: infotheory1
  title: Information Theory 1
  date: 2022-06-20
  description: Notes on what information and entropy are (both intuitively and axiomatically) , basic concepts and results in information theory (mutual information, relative entropy AKA KL divergence, the data processing inequality, etc.), and what the point of source and channel coding is.
  math: true
  type: ["technical"]
  tags: ["maths"]
  sequel: "infotheory2"
  elsewhere: ["https://www.strataoftheworld.com/2022/06/information-theory-1.html"]

- label: infotheory2
  title: Information Theory 2
  date: 2022-06-25
  description: Notes on source coding, a big branch of information theory that deals with compressing information, including an overview of Huffman, arithmetic, and Lempel-Ziv coding, and a proof of the source coding theorem.
  math: true
  type: ["technical"]
  tags: ["maths"]
  prequel: "infotheory1"
  sequel: "infotheory3"
  elsewhere: ["https://www.strataoftheworld.com/2022/06/information-theory-2-source-coding.html"]

- label: infotheory3
  title: "Information Theory 3"
  date: 2022-06-26
  description: "Notes on channel coding, a big branch of information theory that deals with storing information in error-resistant ways, including an overview of Hamming codes, and a proof of the channel coding theorem."
  math: true
  type: ["technical"]
  tags: ["maths"]
  prequel: "infotheory2"
  elsewhere: ["https://www.strataoftheworld.com/2022/06/information-theory-3-channel-coding.html"]

- label: sicp
  title: "Review: Structure and Interpretation of Computer Programs"
  date: 2019-09-08
  description: "The legendary programming book."
  math: false
  type: ["book reviews", "nonfiction"]
  tags: ["computing"]
  elsewhere: ["https://strataoftheworld.blogspot.com/2019/09/review-structure-and-interpretation-of.html", "https://www.lesswrong.com/posts/GAqCiWJBttazYGsJR/review-structure-and-interpretation-of-computer-programs"]

- label: doomsday-machine
  title: "Review: The Doomsday Machine"
  date: 2020-04-23
  description: "An overview of the threats posed by nuclear war, including first-hand accounts of American nuclear war planning during the Cold War."
  math: false
  type: ["book reviews", "nonfiction"]
  tags: ["history"]
  elsewhere: ["https://strataoftheworld.blogspot.com/2020/04/review-doomsday-machine.html", "https://forum.effectivealtruism.org/posts/surPpSDrbnoxwreEd/book-review-the-doomsday-machine-1"]

- label: where-is-my-flying-car
  title: "Review: Where is my Flying Car?"
  date: 2021-03-21
  description: "An argument that flying cars are actually practical and feasible, and more generally that technological progress has been slowed by regulation and modern culture. Includes lots of cool tech speculation."
  math: false
  type: ["book reviews", "nonfiction"]
  tags: ["civilisation"]
  elsewhere: ["https://strataoftheworld.blogspot.com/2021/03/review-where-is-my-flying-car.html"]

- label: internationalists
  title: "Review: The Internationalists"
  date: 2018-06-15
  description: "A legal perspective on the decline of war."
  math: false
  type: ["book reviews", "nonfiction"]
  tags: ["history"]
  elsewhere: ["https://strataoftheworld.blogspot.com/2018/06/review-internationalists-oona-hathaway.html"]

- label: godel-escher-bach
  title: "Review: GÃ¶del, Escher, Bach"
  date: 2018-04-22
  description: "Review of a book that is a clever exploration of ideas about math and cognition."
  math: true
  type: ["book reviews", "nonfiction"]
  tags: ["computing"]
  elsewhere: ["https://strataoftheworld.blogspot.com/2018/04/review-godel-escher-bach-eternal-golden.html"]

- label: short-reviews-biographies-1
  title: "Short reviews - biographies - 1"
  date: 2021-09-30
  description: "Notes on three of Walter Isaacson's biographies."
  math: false
  type: ["book reviews", "nonfiction"]
  tags: ["misc"]
  elsewhere: ["https://strataoftheworld.blogspot.com/2021/09/short-reviews-biographies.html"]

- label: pleasures-of-counting
  title: "Review: The Pleasures of Counting"
  date: 2019-08-20
  description: "A broad, enjoyable, and quirky exploration of the uses of mathematics."
  math: true
  type: ["book reviews", "nonfiction"]
  tags: ["computing"]
  elsewhere: ["https://strataoftheworld.blogspot.com/2019/08/review-pleasures-of-counting.html"]

- label: seeds-of-science
  title: "Review: Seeds of Science"
  date: 2018-12-30
  description: "Why are genetically modified crops so reviled, despite the scientific consensus that they're safe?"
  math: false
  type: ["book reviews", "nonfiction"]
  tags: ["civilisation"]
  elsewhere: ["https://strataoftheworld.blogspot.com/2018/12/review-seeds-of-science-why-we-got-it.html"]

- label: foragers-farmers-fossil-fuels
  title: "Review: Foragers, Farmers, and Fossil Fuels"
  date: 2020-12-17
  description: "How much can the way in which civilisations capture energy shape the values that they adopt?"
  math: false
  type: ["book reviews", "nonfiction"]
  tags: ["civilisation", "history"]
  elsewhere: ["https://strataoftheworld.blogspot.com/2020/12/review-foragers-farmers-and-fossil-fuels.html", "https://www.lesswrong.com/posts/nsFpCGPJ6dfk9uFkR/review-foragers-farmers-and-fossil-fuels"]

- label: understanding-distributional-shift
  title: "Understanding and controlling auto-induced distributional shift"
  date: 2021-12-13
  description: "The input distribution of a supervised machine learning system is modeled as an unchanging thing, and even in reinforcement learning there are types of distributional shift we want to avoid. However, ML systems are part of the world, and often have incentives for changing the distribution of data they act on (for example, changing the set of users or the preferences of those users in an online content recommendation system such that the users become easier to satisfy). A paper by Krueger, Maharaj, and Leike explores such concerns, and especially whether ML systems end up acting on incentives for distributional shift. They invent simple scenarios and see what training setups lead to agents non-myopically act to shift the future distribution, and find that introducing meta-learning alone is enough to cause this, and that sometimes the choice of learning algorithm (e.g. policy gradient vs Q-learning) has perhaps surprising effects on whether or not such incentives are taken. The paper proposes shuffling agents between environments as a solution, but this has its flaws. The topic relates to some concerns with embedded agents and especially myopia."
  math: true
  type: ["technical"]
  tags: ["AI", "computing"]
  elsewhere: ["https://www.lesswrong.com/posts/rTYGMbmEsFkxyyXuR/understanding-and-controlling-auto-induced-distributional", "https://alignmentforum.org/posts/rTYGMbmEsFkxyyXuR/understanding-and-controlling-auto-induced-distributional"]


- label: nand-to-tetris
  title: "Review: From NAND To Tetris"
  date: 2019-08-15
  description: "A fast-paced, concise, yet comprehensive journey from logic gates and DFFs all the way to the implementation of operating systems and high-level programming languages."
  math: true
  type: ["book reviews", "nonfiction"]
  tags: ["computing"]
  elsewhere: ["https://strataoftheworld.blogspot.com/2019/08/review-from-nand-to-tetris.html"]

- label: enlightenment-now
  title: "Review: Enlightenment Now"
  date: 2018-08-29
  description: "A timely reminder that, contrary to the impression generated by constant negative news, not everything is going to hell and many global trends are actually very positive."
  math: false
  type: ["book reviews", "nonfiction"]
  tags: ["civilisation"]
  elsewhere: ["https://strataoftheworld.blogspot.com/2018/08/review-enlightenment-now-steven-pinker.html"]

- label: amusing-ourselves-to-death
  title: "Review: Amusing Ourselves to Death"
  date: 2019-08-01
  description: "How did television affect public discourse, and what does this tell us about new mediums like the internet?"
  math: false
  type: ["book reviews", "nonfiction"]
  tags: ["civilisation"]
  elsewhere: ["https://strataoftheworld.blogspot.com/2019/08/review-amusing-ourselves-to-death.html", "https://www.lesswrong.com/posts/Pix8haJTbkuxPtxpb/review-amusing-ourselves-to-death"]

- label: energy-and-civilization
  title: "Review: Energy and Civilization: A History"
  date: 2018-10-28
  description: "An information-dense book about historical energy use that lives up to its ambitious title."
  math: true
  type: ["book reviews", "nonfiction"]
  tags: ["history", "civilisation"]
  sequel: energy-and-civilization-more
  elsewhere: ["https://strataoftheworld.blogspot.com/2018/10/review-energy-and-civilization-history.html"]

- label: energy-and-civilization-more
  title: "Review addendum: More energy and more civilization"
  date: 2018-10-29
  description: "More thoughts on Energy and Civilization: A History."
  math: false
  type: ["book reviews", "nonfiction"]
  tags: ["history", "civilisation"]
  prequel: "energy-and-civilization"
  elsewhere: ["https://strataoftheworld.blogspot.com/2018/10/more-energy-and-more-civilization.html"]

- label: short-reviews-nonfiction-1
  title: "Short reviews - nonfiction - 1"
  date: 2020-05-09
  description: "Brief notes on various nonfiction books."
  math: false
  type: ["book reviews", "nonfiction"]
  tags: ["misc"]
  sublist: 
    - "Security Engineering"
    - "Origin Story: A Big History of Everything"
    - "The Character of Physical Law"
    - "The Feynman Lectures on Physics"
    - "Founders at Work"
    - "The Great Leveler: Violence and the History of Inequality"
    - "The Strategy of Conflict"
  elsewhere: ["https://strataoftheworld.blogspot.com/2020/05/short-reviews-non-fiction.html"]

- label: diaspora
  title: "Review: Diaspora"
  date: 2019-05-30
  description: "A wild and very well thought-out ride through a far-future world, featuring fictional physics theories plausible enough that they may one day win a Nobel."
  math: false
  type: ["book reviews", "fiction"]
  tags: ["physics"]
  elsewhere: ["https://strataoftheworld.blogspot.com/2019/05/review-diaspora-greg-egan.html"]

- label: permutation-city
  title: "Review: Permutation City"
  date: 2018-05-21
  description: "This book is mostly a sustained thought experiment that extrapolates crazy but internally consistent conclusions from its philosophical premises."
  math: false
  type: ["book reviews", "fiction"]
  tags: ["computing"]
  elsewhere: ["https://strataoftheworld.blogspot.com/2018/05/review-permutation-city-greg-egan.html"]

- label: baroque-cycle
  title: "Review: The Baroque Cycle"
  date: 2018-06-28
  description: "An expansive story about science, finance, politics, and alchemy in the late 1600s and early 1700s. Almost every natural philosopher of the time makes an appearance, with Newton, Leibniz, and Hooke each being significant characters."
  math: false
  type: ["book reviews", "fiction"]
  tags: ["history"]
  elsewhere: ["https://strataoftheworld.blogspot.com/2018/06/review-baroque-cycle-neal-stephenson.html"]

- label: short-reviews-fiction-1
  title: "Short reviews - fiction - 1"
  date: 2020-05-09
  description: "Brief notes on various fiction books."
  math: false
  type: ["book reviews", "fiction"]
  tags: ["misc"]
  sublist:
    - "Unsong"
    - "The Curse of Chalion"
    - "Exhalation"
    - "Summerland"
    - "Cryptonomicon"
  elsewhere: ["https://strataoftheworld.blogspot.com/2020/05/short-reviews-fiction.html"]

- label: growth-and-civilisation
  title: "Growth and civilisation"
  date: 2019-09-27
  description: "A constantly expanding economy is one reason why societal norms and moral values have shifted for the better. If growth ceases, a reversion from norms of value-creation and tolerance back to norms of capturing value from others and defending your own in-group is possible in the long run."
  math: false
  type: ["general"]
  tags: ["civilisation"]
  elsewhere: ["https://strataoftheworld.blogspot.com/2019/09/growth-and-civilisation.html"]

- label: ea-rigour-and-opportunity-in-charity
  title: "EA ideas 1: rigour and opportunity in charity"
  date: 2020-07-24
  description: "Effective altruism is about carefully reasoning how to do the most good. A focus on impartial welfarist good, the effectiveness of our efforts, and open-minded uncertainty-acknowledging reasoning leads to a different picture of charity than the usual, but also one that is more likely to do good."
  math: false
  type: ["general"]
  tags: ["EA"]
  sequel: "ev-and-risk-neutrality"
  elsewhere: ["https://strataoftheworld.blogspot.com/2020/07/ea-ideas-1-rigour-and-opportunity-in.html"]

- label: ev-and-risk-neutrality
  title: "EA ideas 2: expected value and risk neutrality"
  date: 2020-07-25
  description: "A rational agent maximises the expected value of what it cares about. Expected value reasoning is not free of problems, but, outside extreme thought experiments and applied carefully, it clears most of them, including 'Pascal's mugging' (high-stakes, low-probability situations). Expected value reasoning implies risk neutrality. The most effective charity may often be a risky one, and gains from giving may be dominated by a few risky bets."
  math: true
  type: ["general"]
  tags: ["EA"]
  sequel: "ea-uncertainty"
  prequel: "ea-rigour-and-opportunity-in-charity"
  elsewhere: ["https://strataoftheworld.blogspot.com/2020/07/ea-ideas-2-expected-value-and-risk.html"]

- label: ea-uncertainty
  title: "EA ideas 3: uncertainty"
  date: 2020-07-26
  description: "We are uncertain about both what is right and what is true (being mindful of the difference is often important). Moral uncertainty raises the question of how we should act when we have credence in more than one moral theory. Uncertainty about truth has many sources, including ones broader than uncertainty about specific facts, such as our biases or the difficulty of confirming some facts. These uncertainties suggest we are unaware of huge problems and opportunities."
  math: false
  type: ["general"]
  tags: ["EA"]
  sequel: "utilitarianism"
  prequel: "ev-and-risk-neutrality"
  elsewhere: ["https://strataoftheworld.blogspot.com/2020/07/ea-ideas-3-uncertainty.html"]

- label: utilitarianism
  title: "EA ideas 4: utilitarianism"
  date: 2020-08-10
  description: "While not a necessary part of EA thinking, utilitarianism is the most successful description of the core of human ethics so far. In principle (if not practice, due to the complexity of defining utility), it is capable of deciding every moral question, an important property for a moral system. Our moral progress over the past few centuries can be summarised as a transition to more utilitarian morality."
  math: false
  type: ["general"]
  tags: ["EA"]
  prequel: "ea-uncertainty"
  elsewhere: ["https://strataoftheworld.blogspot.com/2020/08/ea-ideas-4-utilitarianism.html"]

- label: technological-progress
  title: "Technological progress"
  date: 2021-03-25
  description: "There are several reasons to think that it's easy to care too little about technological progress. There are many ways we can try to model what technological progress should be like, and hard to figure out which model is right. Which model is right impacts the question of whether technological progress is stagnating, which is also a confusing question. Despite all this confusion, to bring about a good future probably requires that our civilisation gets a lot better at making choices about technology."
  math: false
  type: ["general"]
  tags: ["civilisation"]
  elsewhere: ["https://strataoftheworld.blogspot.com/2021/03/technological-progress.html"]

- label: nuclear-power
  title: "Nuclear power is good"
  date: 2021-03-27
  description: "Nuclear power is seen as dangerous and unclean. In fact, statistics reveal it is equal to wind and solar in both safety and environmental impact, while the health and environmental impacts of fossil fuels (in particular coal) are massive; as bad in lost human life as a Chernobyl a week, and a significant driver of climate change. We should build more nuclear power as fast as we can."
  math: false
  type: ["general"]
  tags: ["civilisation"]
  elsewhere: ["https://strataoftheworld.blogspot.com/2021/03/nuclear-power-is-good.html"]

- label: death-is-bad
  title: "Death is bad"
  date: 2021-10-17
  description: "Surprisingly many people have arguments against making people immortal, ranging from environmentalism to effects on social progress to equality. I argue that technology that can remove the mandatory death sentence that everyone is born with would be good."
  math: false
  type: ["general"]
  tags: ["civilisation"]
  elsewhere: ["https://strataoftheworld.blogspot.com/2021/10/death-is-bad.html"]

- label: ea-in-practice
  title: "Effective Altruism in practice"
  date: 2022-08-20
  description: "EA ideas are discussed in a previous post series, but what does the EA movement/community/whatever actually look like in practice, where did it come from, and whose idea was it to give those philosophy nerds all that money?"
  math: false
  type: ["general"]
  tags: ["EA"]
  elsewhere: ["https://www.strataoftheworld.com/2022/08/effective-altruism-in-practice.html"]

- label: ea-schelling-point
  title: "EA as a Schelling point"
  date: 2022-09-10
  description: "A significant way in which the Effective Altruism community creates value is by acting as a 'focal' or 'Schelling point' where talented, ambitious, and altruistic people tend to gather and can meet each other. It might be useful to think about what optimising for being a Schelling point looks like, and I list some vague thoughts on that."
  math: false
  type: ["general"]
  tags: ["EA"]
  elsewhere: ["https://forum.effectivealtruism.org/posts/g8aBf2oLwDvgd4ovf/much-ea-value-comes-from-being-a-schelling-point", "https://www.strataoftheworld.com/2022/09/ea-as-schelling-point.html"]

- label: ai-risk-intro-1
  title: "AI risk intro 1: advanced AI might be very bad"
  date: 2022-09-11
  description: "The most likely way for human civilisation to be destroyed this century is through advanced AI systems, and in particular misaligned AI systems (rather than just humans using advanced AI for bad ends). This post is meant as an accessible introduction to the arguments."
  math: false
  type: ["general"]
  tags: ["AI"]
  coauthors: ["Callum McDougall"]
  elsewhere: ["https://www.strataoftheworld.com/2022/09/ai-risk-intro-1-advanced-ai-might-be.html", "https://www.lesswrong.com/posts/bJgEMfiD48fEJJxjm/ai-risk-intro-1-advanced-ai-might-be-very-bad"]
  sequel: "ai-risk-intro-2"

- label: ai-risk-intro-2
  title: "AI risk intro 2: solving the problem"
  date: 2022-09-24
  description: "The field of AI alignment is growing but does not yet have a central paradigm. This post surveys the types of work that people are concretely doing to try to reduce risks from advanced AI systems. If you're confused about what this work actually looks like, this post is for you, regardless of your background."
  math: false
  type: ["general"]
  tags: ["AI"]
  coauthors: ["Callum McDougall"]
  elsewhere: ["https://www.strataoftheworld.com/2022/09/ai-risk-intro-2-solving-problem.html", "https://www.lesswrong.com/posts/e889bGfbtbo2qrMmW/ai-risk-intro-2-solving-the-problem"]
  prequel: "ai-risk-intro-1"

- label: research-skill-model
  title: "A model of research skill"
  date: 2024-01-08
  description: "Doing research means answering questions no one yet knows the answer to. This post tries to find and describe the core parts of being good at this"
  math: false
  type: ["general"]
  tags: ["misc"]
  elsewhere: ["https://www.lesswrong.com/posts/NyGgegFATfsyuGFo4/a-model-of-research-skill", "https://www.strataoftheworld.com/2024/01/a-model-of-research-skill.html", "https://forum.effectivealtruism.org/posts/KqTH5Yvxv3LbvcQz2/a-model-of-research-skill"]

- label: positive-visions-for-ai
  title: "Positive visions for AI"
  date: 2024-07-23
  description: "Advanced AI draws nearer, but discussions of how it might go well are strangely lacking. In this post, we try to sketch out some general ways in which successful integration of AI might be very good for society."
  math: false
  type: ["general"]
  tags: ["AI"]
  coauthors: ["Florence Hinder"]
  elsewhere: ["https://www.lesswrong.com/posts/4bBAK39rFypLbQND4/positive-visions-for-ai", "https://www.strataoftheworld.com/2024/07/positive-visions-for-ai.html", "https://forum.effectivealtruism.org/posts/NZTWEoF6iP8J7Wgiv/positive-visions-for-ai"]

- label: human-data-for-alignment
  title: "Deciding not to found a human-data-for-alignment startup"
  date: 2022-09-27
  description: "Matt Putz and I worked together for the first half of summer 2022 to figure out if we should found a startup with the purpose of helping AI alignment researchers get the datasets they need to train their ML models. This post is a summary of our findings, and why we decided to not do it."
  math: false
  type: ["project reports"]
  tags: ["AI"]
  coauthors: ["Matt Putz"]
  elsewhere: ["https://www.strataoftheworld.com/2022/09/deciding-not-to-found-human-data-for.html", "https://www.lesswrong.com/posts/qArDMixsx77a9xL45/why-we-re-not-founding-a-human-data-for-alignment-org-1", "https://forum.effectivealtruism.org/posts/iBeWbfQLA9EKfsdhu/why-we-re-not-founding-a-human-data-for-alignment-org"]

- label: ai-insurance
  title: "Investigating an insurance-for-AI startup"
  date: 2024-09-21
  description: "Flo Hinder and I worked together for a month during summer 2024 to figure out if we should found an insurance startup to mitigate AI risk. We chose not to, but we think someone else should."
  math: true
  type: ["project reports"]
  tags: ["AI"]
  coauthors: ["Florence Hinder"]
  elsewhere: ["https://www.lesswrong.com/posts/WFHg6ecDthErtuAJj/investigating-an-insurance-for-ai-startup", "https://www.strataoftheworld.com/2024/09/investigating-insurance-for-ai-startup.html", "https://forum.effectivealtruism.org/posts/sNCegtuZaHe9BNRdW/investigating-an-insurance-for-ai-startup"]

- label: two-proofs
  title: "Two proofs"
  date: 2019-06-29
  description: "Two accessible, visual, and (dare I say it?) fun proofs of simple mathematical results, carefully explained so they can be followed without a background in maths."
  math: true
  type: ["technical"]
  tags: ["computing"]
  elsewhere: ["https://strataoftheworld.blogspot.com/2019/06/two-proofs.html"]

- label: classical-physics
  title: "Classical physics"
  date: 2019-12-30
  description: "A summary of the form, gist, and 'character' of all fundamental laws of classical physics."
  math: true
  type: ["technical"]
  tags: ["physics"]
  elsewhere: ["https://strataoftheworld.blogspot.com/2019/12/classical-physics.html"]

- label: data-science-1
  title: "Data science 1"
  date: 2020-12-31
  description: "Notes on fundamental data science concepts (notation; some probability laws; maximum likelihood estimation; supervised and unsupervised learning; fitting, interpreting, and visualising linear models; empirical distributions; KL divergence)."
  math: true
  type: ["technical"]
  tags: ["computing"]
  elsewhere: ["https://strataoftheworld.blogspot.com/2020/12/data-science-1.html"]
  sequel: "data-science-2"

- label: data-science-2
  title: "Data science 2"
  date: 2021-01-22
  description: "More data science notes (Monte Carlo methods; Bayesianism and frequentism; randomised computational methods for Bayesian and frequentist calculations; Markov's, Chebyshev's, and Jensen's inequalities; causal diagrams; Markov chains)."
  math: true
  type: ["technical"]
  tags: ["computing"]
  elsewhere: ["https://strataoftheworld.blogspot.com/2021/01/data-science-2.html"]
  prequel: "data-science-1"

- label: lambda-calculus
  title: "Lambda calculus"
  date: 2021-04-25
  description: "The lambda calculus is a simple model of computation (like Turing machines). This post introduces it, shows how to do useful things in it, and works up to a lambda calculus interpreter written in lambda calculus."
  math: true
  type: ["technical"]
  tags: ["computing"]
  elsewhere: ["https://strataoftheworld.blogspot.com/2021/04/lambda-calculus.html", "https://www.lesswrong.com/posts/D4PYwNtYNwsgoixGa/intro-to-hacking-with-the-lambda-calculus"]

- label: disneyland-without-children
  title: "A Disneyland Without Children"
  date: 2023-06-04
  description: "A short story."
  math: false
  type: ["fiction"]

  tags: ["civilisation"]
  elsewhere: ["https://www.lesswrong.com/posts/pk9mofif2jWbc6Tv3/fiction-a-disneyland-without-children", "https://www.strataoftheworld.com/2023/06/a-disneyland-without-children.html", "https://forum.effectivealtruism.org/posts/Ben4xi9W2k9jvnMky/fiction-a-disneyland-without-children"]

- label: powerful-proof-techniques
  title: "Powerful proof techniques"
  date: 2018-09-06
  description: "The summary of this post is left as an exercise for the reader."
  math: true
  type: ["humour"]
  tags: ["maths"]
  elsewhere: ["https://strataoftheworld.blogspot.com/2018/09/powerful-proof-techniques.html"]

- label: ultimate-literary-essay
  title: "The Ultimate Literary Essay"
  date: 2019-06-26
  description: "The academic literary essay that I've always wanted to write."
  math: false
  type: ["humour"]
  tags: ["satire"]
  elsewhere: ["https://strataoftheworld.blogspot.com/2019/06/the-ultimate-literary-essay.html"]
